{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cognitive-giant",
   "metadata": {},
   "source": [
    "## Clustering of homes.\n",
    "Read\n",
    "https://scikit-learn.org/stable/modules/clustering.html#optics\n",
    "\n",
    "https://en.wikipedia.org/wiki/OPTICS_algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alert-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "from scipy.spatial import Delaunay\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString\n",
    "import networkx as nx\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    " \n",
    "FOLDER_FOR_SHAPE_FILES = \"shape_files_for_QGIS\"\n",
    "FOLDER_FOR_CLUSTER_PLOTS = \"cluster_images\"\n",
    "FOLDER_FOR_CLUSTER_TREES = \"cluster_trees\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "direct-black",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "      osm_id  code    fclass  name  type  \\\n",
      "0  194636169  1500  building  None  None   \n",
      "1  194636173  1500  building  None  None   \n",
      "2  194636191  1500  building  None  None   \n",
      "3  194636195  1500  building  None  None   \n",
      "4  194636203  1500  building  None  None   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((-11.36684 7.99306, -11.36680 7...  \n",
      "1  MULTIPOLYGON (((-11.36671 7.99309, -11.36670 7...  \n",
      "2  MULTIPOLYGON (((-11.36670 7.99296, -11.36668 7...  \n",
      "3  MULTIPOLYGON (((-11.36686 7.99279, -11.36679 7...  \n",
      "4  MULTIPOLYGON (((-11.36661 7.99295, -11.36657 7...  \n",
      "CRS is EPSG:4326.\n",
      "      osm_id  code    fclass  name  type  \\\n",
      "0  194636169  1500  building  None  None   \n",
      "1  194636173  1500  building  None  None   \n",
      "2  194636191  1500  building  None  None   \n",
      "3  194636195  1500  building  None  None   \n",
      "4  194636203  1500  building  None  None   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((900638.291 885298.644, 900642....  \n",
      "1  MULTIPOLYGON (((900651.999 885301.877, 900653....  \n",
      "2  MULTIPOLYGON (((900653.180 885288.163, 900656....  \n",
      "3  MULTIPOLYGON (((900635.698 885268.401, 900644....  \n",
      "4  MULTIPOLYGON (((900663.687 885286.250, 900667....  \n",
      "CRS is EPSG:32628.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A sample of buildings, assumed to be buildings to place in ONE distribution grid\n",
    "\n",
    "#buildings = 'SmallSample_OSMbuildings.geojson'\n",
    "buildings = 'SLE_KenemaRadius_OSMBuildings.geojson'\n",
    "print('Loading data...')\n",
    "# Prepare building data - read as geodataframe\n",
    "gdf = gp.read_file(buildings)\n",
    "# Get the number of rows (points) in the GeoDataFrame\n",
    "#no_points = gdf.shape[0]\n",
    "print(gdf.head())\n",
    "gdf.to_file(f\"{FOLDER_FOR_SHAPE_FILES}/buildigs.shp\")\n",
    "print(f\"CRS is {gdf.crs}.\") #CRF: Cooordinate Reference System\n",
    "\n",
    "gdfm=gdf.to_crs(epsg=32628) # See https://epsg.io/32628\n",
    "print(gdfm.head())\n",
    "print(f\"CRS is {gdfm.crs}.\")\n",
    "gdf = gdfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rolled-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get centroid points of building polygons\n",
    "\n",
    "gdf['centroid'] = gdf['geometry'].centroid\n",
    "# Break out lat and long into separate columns of GeoDataFrame\n",
    "gdf['lon'] = gdf.centroid.x\n",
    "gdf['lat'] = gdf.centroid.y\n",
    "# Get lat and long columns from the GeoDataFrame and convert into a numpy array\n",
    "coords = gdf.drop(['name', 'type', 'code', 'fclass', 'osm_id', 'geometry', 'centroid'], axis=1).to_numpy()\n",
    "# You will get a warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "central-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(folder_path):\n",
    "    # Check if the folder already exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        # Create the folder if it doesn't exist\n",
    "        os.makedirs(folder_path)\n",
    "        # print(f\"Folder '{folder_path}' created.\")\n",
    "    # else:\n",
    "    #     # print(f\"Folder '{folder_path}' already exists.\")\n",
    "        \n",
    "\n",
    "def does_file_exist(directory, filename):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    return os.path.exists(file_path)\n",
    "\n",
    "def delete_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    #     print(f\"> The file '{file_path}' has been deleted. Will be recreated.\")\n",
    "    # else:\n",
    "    #     print(f\"> The file '{file_path}' does not exist. Will create a new one.\")\n",
    "\n",
    "def plot_bar_chart(dictionary):\n",
    "    keys = list(dictionary.keys())\n",
    "    values = list(dictionary.values())\n",
    "    # Get the current date and time\n",
    "    current_time = datetime.datetime.now()\n",
    "\n",
    "    # Format the timestamp as a string (optional)\n",
    "    timestamp_str = current_time.strftime(\"%Y%m%d_%H%M%S\")    \n",
    "\n",
    "    plt.bar(keys, values, color='blue')\n",
    "    plt.xlabel('Epsilon Values')\n",
    "    plt.ylabel('Total kilometers of cables')\n",
    "    plt.title('Comparison of cable distances for epsilon values')\n",
    "    plt.savefig(f\"simulation_comparions/cable_estimations_{timestamp_str}.png\")\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Haversine formula for kilometer distance between two lat/long points\n",
    "def euclidean_distance(point1, point2):\n",
    "    (x1, y1) = point1\n",
    "    (x2, y2) = point2\n",
    "    distance = np.sqrt((x1-x2)**2 + (y1-y2)**2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7752d89",
   "metadata": {},
   "source": [
    "## Run the Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c06ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering_for_epsilon_distance(coords, epsilon_distance):\n",
    "    clust = OPTICS(min_samples=10, xi=.05, min_cluster_size=.5)\n",
    "\n",
    "    # Run the fit\n",
    "    # \n",
    "    clust.fit(coords)\n",
    "    labelsOp = clust.labels_\n",
    "    labels = cluster_optics_dbscan(reachability=clust.reachability_,\n",
    "                                    core_distances=clust.core_distances_,\n",
    "                                    ordering=clust.ordering_, eps=epsilon_distance)\n",
    "    num_clusters = len(set(labels))\n",
    "    print(f\"> There are {num_clusters} clusters for epsilon distance {epsilon_distance}.\")\n",
    "\n",
    "\n",
    "\n",
    "    numRepeats = int(num_clusters/7+2)\n",
    "    colors = ['g', 'r', 'b', 'y','m', 'c','m','olive']*numRepeats\n",
    "\n",
    "    # plot outliers\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    plt.scatter(x=coords[labels == -1, 0], y=coords[labels == -1, 1],color='k', s=1, alpha=0.8)\n",
    "\n",
    "    for klass, color in zip(range(0, num_clusters), colors):\n",
    "        plt.scatter(x=coords[labels == klass, 0], y=coords[labels == klass, 1],color=color, s=5, alpha=0.8)\n",
    "    plt.title(f\"Clustering for epsilon distance of {epsilon_distance}\")\n",
    "    plt.savefig(f\"{FOLDER_FOR_CLUSTER_PLOTS}/clusters_for_epsilon_of_{epsilon_distance}.png\")\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d1ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mst_for_cluster(cluster_to_work_with,labels,epsilon):\n",
    "    # print(f\"--Processing cluster {cluster_to_work_with}\")\n",
    "    cluster_to_points = {}\n",
    "    for (point_index, cluster_assignment) in enumerate(labels):\n",
    "        if cluster_assignment not in cluster_to_points:\n",
    "            cluster_to_points[cluster_assignment] = [coords[point_index]]\n",
    "        else:\n",
    "            cluster_to_points[cluster_assignment].append(coords[point_index])\n",
    "\n",
    "\n",
    "\n",
    "    coords_for_current_cluster = cluster_to_points[cluster_to_work_with] if cluster_to_work_with in cluster_to_points else []\n",
    "    xcoords_of_cluster = [x for (x,y) in coords_for_current_cluster]\n",
    "    ycoords_of_cluster = [y for (x,y) in coords_for_current_cluster]\n",
    "    houses_in_cluster = len(coords_for_current_cluster)\n",
    "    \n",
    "\n",
    "    coords_not_in_current_cluster = []\n",
    "    for cluster in cluster_to_points:\n",
    "        if cluster != cluster_to_work_with:\n",
    "            coords_not_in_current_cluster.extend(cluster_to_points[cluster])\n",
    "\n",
    "    xcoords_outside_cluster = [x for (x,y) in coords_not_in_current_cluster]\n",
    "    ycoords_outside_cluster = [y for (x,y) in coords_not_in_current_cluster]\n",
    "\n",
    "\n",
    "\n",
    "    colors = ['g', 'r', 'b', 'y', 'c','m','olive','b','m']*20\n",
    "    # plt.figure(figsize=(7, 7))\n",
    "    #plot points in chosen cluster\n",
    "    # plt.scatter(x=xcoords_of_cluster, y=ycoords_of_cluster,color='r', s=5, alpha=0.8)\n",
    "\n",
    "    # plot outliers\n",
    "    # plt.scatter(x=xcoords_outside_cluster, y=ycoords_outside_cluster,color='k', s=5, alpha=0.8)\n",
    "\n",
    "\n",
    "    no_points = len(coords_for_current_cluster)\n",
    "\n",
    "    #print('Calculating Delaunay triangulation and distance between Delaunay neighbours...')\n",
    "    # Get Delauney triangulation of coordinates\n",
    "    tri = Delaunay(coords_for_current_cluster)\n",
    "    indices = tri.vertex_neighbor_vertices[0]\n",
    "    indptr = tri.vertex_neighbor_vertices[1]\n",
    "\n",
    "    # Instantiate dictionary to hold neighbors of each point & data-frame to hold distances between neighbours\n",
    "    neighbors = {}\n",
    "    locations = {}\n",
    "    distances = pd.DataFrame(columns=[\"source\", \"dest\", \"distance\"])\n",
    "    \n",
    "\n",
    "    # Get dictionary of neighbors of all points and a dictionary of locations of all points\n",
    "    for k in range(0, no_points):\n",
    "        neighbors[k] = indptr[indices[k]:indices[k+1]]\n",
    "        locations[k] = coords_for_current_cluster[k][0], coords_for_current_cluster[k][1]\n",
    "\n",
    "    # Get distances between all Delaunay neighbors\n",
    "    dists = []\n",
    "    for key, values in neighbors.items():\n",
    "        for value in values:\n",
    "            coord_1 = coords_for_current_cluster[key]\n",
    "            coord_2 = coords_for_current_cluster[value]\n",
    "            dist = euclidean_distance(coord_1, coord_2)\n",
    "            dists.append({\n",
    "                \"source\": key, \n",
    "                \"dest\": value, \n",
    "                \"distance\": dist\n",
    "            })\n",
    "    distances = pd.DataFrame(dists)\n",
    "    #print(distances.head())\n",
    "\n",
    "\n",
    "\n",
    "    # Plot Delaunay triangulation\n",
    "    # plt.figure(figsize=(7, 7))\n",
    "    # plt.title('Delaunay Triangulation of Homes')\n",
    "    # plt.triplot(xcoords_of_cluster, ycoords_of_cluster, tri.simplices)\n",
    "    # plt.xlabel('Longitude ')\n",
    "    # plt.ylabel('Latitude ')\n",
    "    # plt.plot(xcoords_of_cluster, ycoords_of_cluster, 'o')\n",
    "    # axes = plt.gca()\n",
    "    # axes.set_xlim([min(xcoords_of_cluster) - 0.001, max(xcoords_of_cluster) + 0.001])\n",
    "    # axes.set_ylim([min(ycoords_of_cluster) - 0.001, max(ycoords_of_cluster) + 0.001])\n",
    "\n",
    "\n",
    "\n",
    "    #print('Creating a graph from this information (edge weight = distance)...')\n",
    "    G = nx.Graph()\n",
    "    for index, row in distances.iterrows():\n",
    "        G.add_edge(row['source'], row['dest'], weight=row['distance'])\n",
    "\n",
    "    #print('Calculating the minimum spanning tree of the graph...')\n",
    "    T = nx.minimum_spanning_tree(G)\n",
    "\n",
    "    edges = T.edges(data=True)\n",
    "    weights = [x[2]['weight'] for x in edges]\n",
    "    total_dist = sum(weights)\n",
    "\n",
    "    #print('Number of nodes (buildings) in the graph: ', T.number_of_nodes())\n",
    "    #print('Number of edges in the minimum spanning tree: ', T.number_of_edges())\n",
    "    # print('--Total distance of minimum spanning tree (in km): ', total_dist)\n",
    "\n",
    "    # Create a geopandas dataframe and save as .shp\n",
    "\n",
    "    # create an array of LineString from T\n",
    "    lines = []\n",
    "    for (i,edge) in enumerate(edges):\n",
    "        point_a = coords_for_current_cluster[int(edge[0])]\n",
    "        point_b = coords_for_current_cluster[int(edge[1])]\n",
    "        line = LineString([point_a, point_b])\n",
    "        lines.append(line)\n",
    "\n",
    "    d = {'geometry':lines}\n",
    "    mstDF = gp.GeoDataFrame(d, crs=\"EPSG:32628\")\n",
    "    shape_file_name = f\"{FOLDER_FOR_SHAPE_FILES}/sierra_leone_epsilon_{epsilon}.shp\"\n",
    "\n",
    "    if does_file_exist(\".\",shape_file_name):\n",
    "        #append \n",
    "        existing_shape = gp.read_file(shape_file_name)\n",
    "        gdf_combined = gp.GeoDataFrame(pd.concat([existing_shape, mstDF]))\n",
    "        gdf_combined.to_file(shape_file_name)\n",
    "    else:\n",
    "        mstDF.to_file(shape_file_name)\n",
    "        \n",
    "    # print('Plotting results:')\n",
    "    # Plot Minimum Spanning Tree made from Delaunay Triangulation\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    nx.draw_networkx(T, pos=locations, with_labels=False, node_size=15)\n",
    "    plt.title(f\"MST for Cluster {cluster_to_work_with} of Epsilon {epsilon}. Points Covered: {houses_in_cluster}\")\n",
    "    plt.xlabel('Longitude ')\n",
    "    plt.ylabel('Latitude')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([min(xcoords_of_cluster) - 0.001, max(xcoords_of_cluster) + 0.001])\n",
    "    axes.set_ylim([min(ycoords_of_cluster) - 0.001, max(ycoords_of_cluster) + 0.001])\n",
    "    folder_for_cluster = f\"{FOLDER_FOR_CLUSTER_TREES}_for_epsilon_{epsilon}\"\n",
    "    create_folder(folder_for_cluster)\n",
    "    plt.savefig(f\"{folder_for_cluster}/cluster{cluster_to_work_with}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Plot relative frequency of edge distances in minimum spanning tree\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(weights, bins=200)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('Number of edges of this distance')\n",
    "    plt.xlabel('Distance (km)')\n",
    "    plt.savefig(f\"{folder_for_cluster}/edge_frequencies_cluster{cluster_to_work_with}.png\")\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "    return total_dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b968c",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "The following code runs the clustering algorithm for a set of epsilon distances\n",
    "\n",
    " 1. Modify the `epsilons_to_test` list to include epsilon distances you want to test. Note that each simulation can take several minutes depending on your computer's memory and processor constraints. Running five simulations can take an hour! Running one to two epsilon values at a time is recommended.\n",
    "\n",
    "2. Look for the \"Finished running all epsilon clusterings.\" message to ensure the runs have finished\n",
    "3. After the conclusion, you will have a set of output files that you can use to continue your analysis:\n",
    "- For the shape files to load onto QGIS, look into the `shape_files_for_QGIS/` folder\n",
    "- To visualize the clusters for different epsilon values, look into the `cluster_images/` folder\n",
    "- To see a bar graph comparing runs, look at the `simulations_comparisons/` folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a4a863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Will test 1 epsilon value(s).\n",
      "> Starting clustering run 1 of 1 for epsilon value of 250...\n",
      "> The file 'shape_files_for_QGIS/sierra_leone_epsilon_250.shp' has been deleted. Will be recreated.\n",
      "> There are 296 clusters for epsilon distance 250.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing clusters:  61%|██████    | 179/295 [05:17<05:32,  2.87s/cluster]"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "epsilons_to_test = [250] # <-- change this to test different epsilon values\n",
    "num_epsilons = len(epsilons_to_test)\n",
    "\n",
    "print (f\"> Will test {num_epsilons} epsilon value(s).\")\n",
    "for (epsilon_i,epsilon) in enumerate(epsilons_to_test):\n",
    "    print(f\"> Starting clustering run {epsilon_i + 1} of {num_epsilons} for epsilon value of {epsilon}...\")\n",
    "    shape_file_name = f\"{FOLDER_FOR_SHAPE_FILES}/sierra_leone_epsilon_{epsilon}.shp\"\n",
    "    delete_file(shape_file_name)\n",
    "    labels = run_clustering_for_epsilon_distance(coords, epsilon)\n",
    "    num_clusters = len(set(labels))\n",
    "    total_cable_distance = 0\n",
    "\n",
    "    for i in tqdm(range(num_clusters - 1), desc=\"Processing clusters\", unit=\"cluster\"):\n",
    "        total_cable_distance += process_mst_for_cluster(i, labels, epsilon)\n",
    "\n",
    "\n",
    "    results[f\"E={epsilon}\"] = total_cable_distance\n",
    "    print(f\"Total cable distance for epsilon {epsilon} is {total_cable_distance} km.\")\n",
    "print(\"Finished running all epsilon clusterings.\")\n",
    "plot_bar_chart(results)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
